{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Karin.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEHcB3kqyHZ6",
        "colab_type": "code",
        "outputId": "711b01bc-eb15-42da-fc7a-c074c4910559",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# After every epoch the function goes here and checks if the accuracy is over 99%.\n",
        "#The log is an object the result of describing every iteration.\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.99): # TODO - Change this to get the required accuracy\n",
        "      print(\"\\nReached 99% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "# Training set database - photos of\n",
        "mnist = tf.keras.datasets.mnist\n",
        
        "# Fill traing database into variables - the function divides the set into 2 sets:\n",
        "# train and test and uses the train to learn examples and the test to test its accuracy\n",
        "# x - input, y - output\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "callbacks = myCallback()\n",
        "\n",
        "\n",
        "# model = tf.keras.models.Sequential([\n",
        "#   tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "#   tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "#   tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "# ])\n",
        "# The model is the learning object - the sequence of learning is:\n",
        "model = tf.keras.models.Sequential()\n",
        "# Takes an array of 28*28 and turns it to a one dimensional array.\n",
        "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "# Adds to the probabilaty of important features according to the training.\n",
        "model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
        "\n",
        "# Insert parameters for learning from training set\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# An epoch is an iteration over the entire training and test data provided. The\n",
        "# model not trained for a number of iterations given by epochs, but merely until\n",
        "# the epoch of index epochs is reached.\n",
        "model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Train on 60000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 10s 162us/sample - loss: 0.2012 - acc: 0.9404\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 10s 159us/sample - loss: 0.0800 - acc: 0.9756\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 10s 161us/sample - loss: 0.0529 - acc: 0.9832\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 9s 150us/sample - loss: 0.0370 - acc: 0.9886\n",
            "Epoch 5/10\n",
            "59616/60000 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9913\n",
            "Reached 99% accuracy so cancelling training!\n",
            "60000/60000 [==============================] - 9s 153us/sample - loss: 0.0269 - acc: 0.9913\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3e7cc07e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6I5fv4U8CyQq",
        "colab_type": "code",
        "outputId": "fc963cba-f02a-401f-85ed-aec106492dd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "import numpy\n",
        "\n",
        "currImg = x_test[2] # TODO - Alter this for different photos\n",
        "#Creats a 3D array \n",
        "currImgArr = currImg[numpy.newaxis, ...]\n",
        "\n",
        "#The function reads the number in the picture\n",
        "predictedNum = numpy.argmax(model.predict(currImgArr))\n",
        "print(\"The string is: \", predictedNum)\n",
        "\n",
        "#Presenting the picture\n",
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(currImg, interpolation='nearest')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The string is:  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlOGXijL8UlGGXyrK8EtFGX6pKMMvFfX/98XKu6yssugAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGWEhKJU_aSi",
        "colab_type": "code",
        "outputId": "236e2255-cbd7-46ac-f82c-063a1b7cfeb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "\n",
        "import numpy\n",
        "import PIL\n",
        "import cv2\n",
        "\n",
        "currImg = '/content/2.png' #TODO - Alter this for different photos\n",
        "\n",
        "print(\"Processing image\")  \n",
        "#loading the image\n",
        "im = cv2.imread(currImg, 0) \n",
        "print(im.shape) \n",
        "#Turns the image to the size of 28*28\n",
        "im = cv2.resize(im,  (28, 28))\n",
        "print(model.predict(im.reshape(1,28,28)))\n",
        "numpy.argmax(model.predict(im.reshape(1,28,28)))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing image\n",
            "(3500, 3500)\n",
            "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    }
  ]
}
